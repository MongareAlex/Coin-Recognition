{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHODOLOGY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For The Implementation of a solution to the coin classification problem ,We took an approach of using a simple neural network to classify the coins.\n",
    "\n",
    "#### DATA\n",
    "\n",
    "The network is trained on a dataset of coin images that are taken using an array of capturing devices including a webcam,a phone camera and a DLSR camera.\n",
    "The network is then tested on an image containing the coins and its accuracy computed.\n",
    "\n",
    "Coins.\n",
    "\n",
    "\n",
    "\n",
    "##### Data Preparation\n",
    "As indicated above,for the training of the network,We required the individual coin images to be labeled and since we could not get a public dataset on Kenyan shilling coins,we resorted to manually labelling our coins for the purposes of identifying their classes.\n",
    "\n",
    "We created a dataset that had the classes that defined the material/texture of the coins.\n",
    "\n",
    "\n",
    "#### IMPLEMENTATION\n",
    "\n",
    "The solution is based on the use of the openCV library and python for the image processing and a simple neural network classifier that trains based on the aspects of the coins' material and then tries to classify the coins in  an existing image and their value.\n",
    "\n",
    "We import the required modules for the working of our  model including modules from scikit for the classification of the images,numpy for the manipylation of arrays and image matrices and the cv library for the purposes described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import argparse\n",
    "import glob\n",
    "import warnings \n",
    "import cv2\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# construct argument parser and parse arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True, help=\"path to image\")\n",
    "args = vars(ap.parse_args())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image Pre-processing\n",
    "\n",
    "The image is passed as a parameter via the terminal and is parsed into the program form where the pre processing is done in readiness for the later stages.\n",
    "\n",
    "The initial image is first resized while maintaining its aspects ratio.\n",
    "The image is then converted to grayscale, as this works best for image processing.\n",
    "\n",
    "\n",
    "For the detection of the Coins in the image a canny edge detection algorithm is employed and some of the steps for the canny edge deatection include:\n",
    "\n",
    "   1.Noise Reduction.\n",
    "       This involves  performing  a median blur on the layer, and then we apply an adaptive thresholding using the gaussian algorithm.\n",
    "       The image's contrast is also improved to account for differences in lighting conditions\n",
    "       \n",
    "\n",
    "   2.Finding Intensity Gradient of the Image.\n",
    "   Smoothened image is then filtered with a Sobel kernel in both horizontal and vertical direction to get first derivative in horizontal direction ( Gx) and vertical direction\n",
    "   \n",
    "   \n",
    "   3.Non-maximum Suppression\n",
    "   \n",
    "   After getting gradient magnitude and direction, a full scan of image is done to remove any unwanted pixels which may not constitute the edge. For this, at every pixel, pixel is checked if it is a local maximum in its neighborhood in the direction of gradient\n",
    "   \n",
    "   \n",
    "   4.Hysteresis Thresholding\n",
    "   This stage decides which are all edges are really edges and which are not. For this, we need two threshold values, minVal and maxVal. Any edges with intensity gradient more than maxVal are sure to be edges and those below minVal are sure to be non-edges, so discarded. Those who lie between these two thresholds are classified edges or non-edges based on their connectivity. If they are connected to \"sure-edge\" pixels, they are considered to be part of edges. Otherwise, they are also discarded.\n",
    "   \n",
    "   \n",
    "   The Canny edge detection algorithm together with the Houghton algorithm are used to detect the edges of the circles in the training dataset too.The above steps are followed .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread(args[\"image\"])\n",
    "\n",
    "d = 1024 / image.shape[1]\n",
    "dim = (1024, int(image.shape[0] * d))\n",
    "image = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "output = image.copy()\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# create a CLAHE object to apply contrast limiting adaptive histogram equalization\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "gray = clahe.apply(gray)\n",
    "\n",
    "\n",
    "def calcHistogram(img):\n",
    "    # create mask\n",
    "    m = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
    "    (w, h) = (int(img.shape[1] / 2), int(img.shape[0] / 2))\n",
    "    cv2.circle(m, (w, h), 60, 255, -1)\n",
    "\n",
    "    # calcHist expects a list of images, color channels, mask, bins, ranges\n",
    "    h = cv2.calcHist([img], [0, 1, 2], m, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "\n",
    "    # return normalized \"flattened\" histogram\n",
    "    return cv2.normalize(h, h).flatten()\n",
    "\n",
    "\n",
    "def calcHistFromFile(file):\n",
    "    img = cv2.imread(file)\n",
    "    return calcHistogram(img)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification\n",
    "\n",
    "We use a simple multi_layer perceptron to classify the coins.\n",
    "The coins are grouped and labelled acoording to the denominations of Kenyan coins:\n",
    "   * 1 shilling\n",
    "   * 5 shilling\n",
    "   * 10 shilling\n",
    "   * 20 shilling\n",
    "   * 40 shilling\n",
    "   \n",
    "   The network trains on the input images' material/texture and classifies them as ineither of the above denominations or unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enum(tuple): __getattr__ = tuple.index\n",
    "\n",
    "\n",
    "# Enumerate material types for use in classifier\n",
    "Material = Enum(('1silling', '5shiling', '10shiling', '20shiling','40shiling'))\n",
    "\n",
    "# locate sample image files\n",
    "sample_images_silver1 = glob.glob(\"sample_images/1/*\")\n",
    "sample_images_silver5 = glob.glob(\"sample_images/5/*\")\n",
    "sample_images_silver10 = glob.glob(\"sample_images/10/*\")\n",
    "sample_images_silver20 = glob.glob(\"sample_images/20/*\")\n",
    "sample_images_silver40 = glob.glob(\"sample_images/40/*\")\n",
    "\n",
    "# define training data and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# compute and store training data and labels\n",
    "for i in sample_images_silver1:\n",
    "    X.append(calcHistFromFile(i))\n",
    "    y.append(Material.1shiling)\n",
    "for i in sample_images_silver5:\n",
    "    X.append(calcHistFromFile(i))\n",
    "    y.append(Material.5shiling)\n",
    "for i in sample_images_silver10:\n",
    "    X.append(calcHistFromFile(i))\n",
    "    y.append(Material.10shiling)\n",
    "for i in sample_images_silver20:\n",
    "    X.append(calcHistFromFile(i))\n",
    "    y.append(Material.20shiling)\n",
    "for i in sample_images_silver40:\n",
    "    X.append(calcHistFromFile(i))\n",
    "    y.append(Material.40shiling)\n",
    "\n",
    "# instantiate classifier\n",
    "# Multi-layer Perceptron\n",
    "# score: 0.974137931034\n",
    "clf = MLPClassifier(solver=\"lbfgs\")\n",
    "\n",
    "# split samples into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.2)\n",
    "\n",
    "# train and score classifier\n",
    "clf.fit(X_train, y_train)\n",
    "score = int(clf.score(X_test, y_test) * 100)\n",
    "print(\"Classifier mean accuracy: \", score)\n",
    "\n",
    "# blur the image using Gaussian blurring, where pixels closer to the center\n",
    "# contribute more \"weight\" to the average, first argument is the source image,\n",
    "# second argument is kernel size, third one is sigma (0 for autodetect)\n",
    "# we use a 7x7 kernel and let OpenCV detect sigma\n",
    "blurred = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "# circles: A vector that stores x, y, r for each detected circle.\n",
    "# src_gray: Input image (grayscale)\n",
    "# CV_HOUGH_GRADIENT: Defines the detection method.\n",
    "# dp = 2.2: The inverse ratio of resolution\n",
    "# min_dist = 100: Minimum distance between detected centers\n",
    "# param_1 = 200: Upper threshold for the internal Canny edge detector\n",
    "# param_2 = 100*: Threshold for center detection.\n",
    "# min_radius = 50: Minimum radius to be detected.\n",
    "# max_radius = 120: Maximum radius to be detected.\n",
    "circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=2.2, minDist=100,\n",
    "                           param1=200, param2=100, minRadius=50, maxRadius=120)\n",
    "\n",
    "\n",
    "def predictMaterial(roi):\n",
    "    # calculate feature vector for region of interest\n",
    "    hist = calcHistogram(roi)\n",
    "\n",
    "    # predict material type\n",
    "    s = clf.predict([hist])\n",
    "\n",
    "    # return predicted material type\n",
    "    return Material[int(s)]\n",
    "\n",
    "\n",
    "# todo: refactor\n",
    "diameter = []\n",
    "materials = []\n",
    "coordinates = []\n",
    "\n",
    "count = 0\n",
    "if circles is not None:\n",
    "    # append radius to list of diameters (we don't bother to multiply by 2)\n",
    "    for (x, y, r) in circles[0, :]:\n",
    "        diameter.append(r)\n",
    "\n",
    "    # convert coordinates and radii to integers\n",
    "    circles = np.round(circles[0, :]).astype(\"int\")\n",
    "\n",
    "    # loop over coordinates and radii of the circles\n",
    "    for (x, y, d) in circles:\n",
    "        count += 1\n",
    "\n",
    "        # add coordinates to list\n",
    "        coordinates.append((x, y))\n",
    "\n",
    "        # extract region of interest\n",
    "        roi = image[y - d:y + d, x - d:x + d]\n",
    "\n",
    "        # try recognition of material type and add result to list\n",
    "        material = predictMaterial(roi)\n",
    "        materials.append(material)\n",
    "\n",
    "        # write masked coin to file\n",
    "        if False:\n",
    "            m = np.zeros(roi.shape[:2], dtype=\"uint8\")\n",
    "            w = int(roi.shape[1] / 2)\n",
    "            h = int(roi.shape[0] / 2)\n",
    "            cv2.circle(m, (w, h), d, (255), -1)\n",
    "            maskedCoin = cv2.bitwise_and(roi, roi, mask=m)\n",
    "            cv2.imwrite(\"extracted/01coin{}.png\".format(count), maskedCoin)\n",
    "\n",
    "        # draw contour and results in the output image\n",
    "        cv2.circle(output, (x, y), d, (0, 255, 0), 2)\n",
    "        cv2.putText(output, material,\n",
    "                    (x - 40, y), cv2.FONT_HERSHEY_PLAIN,\n",
    "                    1.5, (0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "# get biggest diameter\n",
    "biggest = max(diameter)\n",
    "i = diameter.index(biggest)\n",
    "\n",
    "# scale everything according to maximum diameter\n",
    "# todo: this should be chosen by the user\n",
    "if materials[i] == \"1shiling\":\n",
    "    diameter = [x / biggest * 23.9 for x in diameter]\n",
    "    scaledTo = \"Scaled to silver1\"\n",
    "elif materials[i] == \"5shiling\":\n",
    "    diameter = [x / biggest * 19.5 for x in diameter]\n",
    "    scaledTo = \"Scaled to silver5\"\n",
    "elif materials[i] == \"10shiling\":\n",
    "    diameter = [x / biggest * 23.00 for x in diameter]\n",
    "    scaledTo = \"Scaled to silver10\"\n",
    "elif materials[i] == \"20shiling\":\n",
    "    diameter = [x / biggest * 26.0 for x in diameter]\n",
    "    scaledTo = \"Scaled to silver20\"\n",
    "elif materials[i] == \"40shiling\":\n",
    "    diameter = [x / biggest * 27.5 for x in diameter]\n",
    "    scaledTo = \"Scaled to silver40\"\n",
    "else:\n",
    "    scaledTo = \"unable to scale..\"\n",
    "\n",
    "i = 0\n",
    "total = 0\n",
    "while i < len(diameter):\n",
    "    d = diameter[i]\n",
    "    m = materials[i]\n",
    "    (x, y) = coordinates[i]\n",
    "    t = \"Unknown\"\n",
    "\n",
    "    # compare to known diameters with some margin for error\n",
    "    if math.isclose(d, 23.9, abs_tol=1.25) and m == \"1shiling\":\n",
    "        t = \"1 bob\"\n",
    "        total +=1 \n",
    "    \n",
    "    elif math.isclose(d, 19.5, abs_tol=1.25) and m == \"5shiling\":\n",
    "        t = \"5 bob\"\n",
    "        total += 5\n",
    "    elif math.isclose(d, 23.00, abs_tol=1.0) and m == \"10shiling\":\n",
    "        t = \"10 bob\"\n",
    "        total += 10\n",
    "    elif math.isclose(d, 26.00, abs_tol=1.2) and m == \"20shiling\":\n",
    "        t = \"20 bob\"\n",
    "        total += 20\n",
    "    elif math.isclose(d, 27.5, abs_tol=1.10) and m == \"40shiling\":\n",
    "        t = \"40 bob\"\n",
    "        total += 40\n",
    "    \n",
    "\n",
    "    # write result on output image\n",
    "    cv2.putText(output, t,\n",
    "                (x - 40, y + 22), cv2.FONT_HERSHEY_PLAIN,\n",
    "                1.5, (255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "    i += 1\n",
    "\n",
    "# resize output image while retaining aspect ratio\n",
    "d = 768 / output.shape[1]\n",
    "dim = (768, int(output.shape[0] * d))\n",
    "image = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "output = cv2.resize(output, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# write summary on output image\n",
    "cv2.putText(output, scaledTo,\n",
    "            (5, output.shape[0] - 40), cv2.FONT_HERSHEY_PLAIN,\n",
    "            1.0, (0, 0, 255), lineType=cv2.LINE_AA)\n",
    "cv2.putText(output, \"Coins detected: {}, EUR {:2}\".format(count, total / 100),\n",
    "            (5, output.shape[0] - 24), cv2.FONT_HERSHEY_PLAIN,\n",
    "            1.0, (0, 0, 255), lineType=cv2.LINE_AA)\n",
    "cv2.putText(output, \"Classifier mean accuracy: {}%\".format(score),\n",
    "            (5, output.shape[0] - 8), cv2.FONT_HERSHEY_PLAIN,\n",
    "            1.0, (0, 0, 255), lineType=cv2.LINE_AA)\n",
    "\n",
    "# show output and wait for key to terminate program\n",
    "cv2.imshow(\"Output\", np.hstack([image, output]))\n",
    "cv2.waitKey(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
